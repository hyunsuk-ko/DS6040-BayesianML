{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import QDA_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143</td>\n",
       "      <td>261</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>151</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506</td>\n",
       "      <td>92</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  duration   y\n",
       "0   58     2143       261  no\n",
       "1   44       29       151  no\n",
       "2   33        2        76  no\n",
       "3   47     1506        92  no\n",
       "4   33        1       198  no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_full = pd.read_csv(\"bank-full.csv\")\n",
    "bank_full = bank_full[['age', 'balance', 'duration', 'y']]\n",
    "bank_full.to_csv(\"bank-partial.csv\", index = False)\n",
    "bank = pd.read_csv(\"bank-partial.csv\")\n",
    "bank.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Gaussian class conditional likelihoods with unequal varaince-covariance matrix: QDA\n",
    "\n",
    "- Equal class priors and equal costs for misclassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods:  [2.10302060e-09 1.09725319e-09]\n",
      "\n",
      "QDA Predicted Class: no\n",
      "\n",
      "QDA Class Likelihoods:\n",
      "no: 2.1030206042712077e-09\n",
      "yes: 1.0972531944110306e-09\n",
      "\n",
      "QDA probabilities: \n",
      "{'no': 1.0515103021356039e-09, 'yes': 5.486265972055153e-10}\n",
      "\n",
      "Decision: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_qda = QDA_code.QDA('bank-partial.csv')\n",
    "\n",
    "observation = [58, 261, 261]\n",
    "model_qda.compute_likelihoods(observation)\n",
    "\n",
    "given_priors = {\n",
    "    \"no\": 1 / 2,\n",
    "    \"yes\": 1 / 2,\n",
    "}\n",
    "\n",
    "model_qda.compute_probabilities(observation, given_priors)\n",
    "model_qda.decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prior for not selecting the new bank service is 0.9 and misclassification costs are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods:  [2.10302060e-09 1.09725319e-09]\n",
      "\n",
      "QDA Predicted Class: no\n",
      "\n",
      "QDA Class Likelihoods:\n",
      "no: 2.1030206042712077e-09\n",
      "yes: 1.0972531944110306e-09\n",
      "\n",
      "QDA probabilities: \n",
      "{'no': 1.892718543844087e-09, 'yes': 1.0972531944110307e-10}\n",
      "\n",
      "Decision: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_qda2 = QDA_code.QDA('bank-partial.csv')\n",
    "\n",
    "observation = [58, 261, 261]\n",
    "model_qda2.compute_likelihoods(observation)\n",
    "\n",
    "given_priors = {\n",
    "    \"no\": 0.9,\n",
    "    \"yes\": 0.1,\n",
    "}\n",
    "\n",
    "model_qda2.compute_probabilities(observation, given_priors)\n",
    "model_qda2.decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prior for not selecting the new bank service is 0.9 and the cost of classifying a customer as not a new service candidate when they are is 15 times the cost of classifying a customer as a new service customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods:  [2.10302060e-09 1.09725319e-09]\n",
      "\n",
      "QDA Predicted Class: no\n",
      "\n",
      "QDA Class Likelihoods:\n",
      "no: 2.1030206042712077e-09\n",
      "yes: 1.0972531944110306e-09\n",
      "\n",
      "QDA probabilities: \n",
      "{'no': 1.892718543844087e-09, 'yes': 1.0972531944110307e-10}\n",
      "\n",
      "QDA Costs: \n",
      "No:  1.892718543844087e-09\n",
      "Yes:  1.645879791616546e-09\n",
      "\n",
      "Decision: yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_qda3 = QDA_code.QDA('bank-partial.csv')\n",
    "\n",
    "observation = [58, 261, 261]\n",
    "model_qda3.compute_likelihoods(observation)\n",
    "\n",
    "given_priors = {\n",
    "    \"no\": 0.9,\n",
    "    \"yes\": 0.1,\n",
    "}\n",
    "\n",
    "cost = {'TP': 0, 'FP': 1, 'FN': 15, 'TN': 0}\n",
    "\n",
    "model_qda3.compute_probabilities(observation, given_priors)\n",
    "model_qda3.cost_decision(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Gaussian class conditional likelihoods with equal varaince-covariance matrix: LDA\n",
    "\n",
    "- Equal class priors and equal costs for misclassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Predicted Class: no\n",
      "LDA Class Likelihoods:\n",
      "no: 1.956466109661075e-09\n",
      "yes: 1.0728059317829899e-09\n",
      "LDA probabilities: \n",
      "{'no': 9.782330548305375e-10, 'yes': 5.364029658914949e-10}\n",
      "\n",
      "Decision: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import LDA_code\n",
    "\n",
    "model_lda = LDA_code.LDA('bank-partial.csv')\n",
    "\n",
    "observation = [58, 261, 261]\n",
    "model_lda.compute_likelihoods(observation)\n",
    "\n",
    "given_priors = {\n",
    "    \"no\": 1 / 2,\n",
    "    \"yes\": 1 / 2,\n",
    "}\n",
    "\n",
    "model_lda.compute_probabilities(observation, given_priors)\n",
    "model_lda.decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prior for not selecting the new bank service is 0.9 and misclassification costs are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Predicted Class: no\n",
      "LDA Class Likelihoods:\n",
      "no: 1.956466109661075e-09\n",
      "yes: 1.0728059317829899e-09\n",
      "LDA probabilities: \n",
      "{'no': 1.7608194986949675e-09, 'yes': 1.0728059317829899e-10}\n",
      "\n",
      "Decision: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lda = LDA_code.LDA('bank-partial.csv')\n",
    "\n",
    "observation = [58, 261, 261]\n",
    "model_lda.compute_likelihoods(observation)\n",
    "\n",
    "given_priors = {\n",
    "    \"no\": 0.9,\n",
    "    \"yes\": 0.1,\n",
    "}\n",
    "\n",
    "model_lda.compute_probabilities(observation, given_priors)\n",
    "model_lda.decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prior for not selecting the new bank service is 0.9 and the cost of classifying a customer as not a new service candidate when they are is 15 times the cost of classifying a customer as a new service customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Predicted Class: no\n",
      "LDA Class Likelihoods:\n",
      "no: 1.956466109661075e-09\n",
      "yes: 1.0728059317829899e-09\n",
      "LDA probabilities: \n",
      "{'no': 1.7608194986949675e-09, 'yes': 1.0728059317829899e-10}\n",
      "\n",
      "LDA Costs: \n",
      "No:  1.7608194986949675e-09\n",
      "Yes:  1.0728059317829899e-10\n",
      "\n",
      "Decision: yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lda = LDA_code.LDA('bank-partial.csv')\n",
    "\n",
    "observation = [58, 261, 261]\n",
    "model_lda.compute_likelihoods(observation)\n",
    "\n",
    "given_priors = {\n",
    "    \"no\": 0.9,\n",
    "    \"yes\": 0.1,\n",
    "}\n",
    "\n",
    "cost = {'TP': 0, 'FP': 1, 'FN': 15, 'TN': 0}\n",
    "\n",
    "model_lda.compute_probabilities(observation, given_priors)\n",
    "model_lda.cost_decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edible_class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>PINK</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>PURPLE</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>CONVEX</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>ALMOND</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>NARROW</td>\n",
       "      <td>PINK</td>\n",
       "      <td>...</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SEVERAL</td>\n",
       "      <td>WOODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  edible_class cap-shape cap-surface cap-color  bruises    odor  \\\n",
       "0       EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "1       EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "2       EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
       "\n",
       "  gill-attachment gill-spacing  gill-size gill-color  ...  \\\n",
       "0            FREE       CROWDED    NARROW      WHITE  ...   \n",
       "1            FREE       CROWDED    NARROW       PINK  ...   \n",
       "2            FREE       CROWDED    NARROW       PINK  ...   \n",
       "\n",
       "  stalk-surface-below-ring stalk-color-above-ring stalk-color-below-ring  \\\n",
       "0                   SMOOTH                  WHITE                  WHITE   \n",
       "1                   SMOOTH                  WHITE                  WHITE   \n",
       "2                   SMOOTH                  WHITE                  WHITE   \n",
       "\n",
       "  veil-type veil-color ring-number ring-type spore-print-color population  \\\n",
       "0   PARTIAL      WHITE         ONE   PENDANT             BROWN    SEVERAL   \n",
       "1   PARTIAL      WHITE         ONE   PENDANT            PURPLE    SEVERAL   \n",
       "2   PARTIAL      WHITE         ONE   PENDANT             BROWN    SEVERAL   \n",
       "\n",
       "  habitat  \n",
       "0   WOODS  \n",
       "1   WOODS  \n",
       "2   WOODS  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom_columns = list(pd.read_csv(\"MushroomVariables.txt\", sep=\",\").columns)\n",
    "mushroom = pd.read_csv(\"MushroomData.csv\").dropna()\n",
    "mushroom.columns = mushroom_columns\n",
    "mushroom.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mushroom.drop([\"edible_class\"], axis = 1)\n",
    "y = mushroom[['edible_class']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>edible_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>FLAT</td>\n",
       "      <td>FIBROUS</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CROWDED</td>\n",
       "      <td>BROAD</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>TAPERING</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>EVANESCENT</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>SCATTERED</td>\n",
       "      <td>GRASSES</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>FLAT</td>\n",
       "      <td>FIBROUS</td>\n",
       "      <td>GRAY</td>\n",
       "      <td>NO</td>\n",
       "      <td>FOUL</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CLOSE</td>\n",
       "      <td>BROAD</td>\n",
       "      <td>CHOCOLATE</td>\n",
       "      <td>ENLARGING</td>\n",
       "      <td>...</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>CHOCOLATE</td>\n",
       "      <td>SOLITARY</td>\n",
       "      <td>PATHS</td>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>CONVEX</td>\n",
       "      <td>FIBROUS</td>\n",
       "      <td>GRAY</td>\n",
       "      <td>BRUISES</td>\n",
       "      <td>NONE</td>\n",
       "      <td>FREE</td>\n",
       "      <td>CLOSE</td>\n",
       "      <td>BROAD</td>\n",
       "      <td>PURPLE</td>\n",
       "      <td>TAPERING</td>\n",
       "      <td>...</td>\n",
       "      <td>GRAY</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>PARTIAL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ONE</td>\n",
       "      <td>PENDANT</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SOLITARY</td>\n",
       "      <td>WOODS</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cap-shape cap-surface cap-color  bruises  odor gill-attachment  \\\n",
       "1971      FLAT     FIBROUS     WHITE       NO  NONE            FREE   \n",
       "4900      FLAT     FIBROUS      GRAY       NO  FOUL            FREE   \n",
       "2273    CONVEX     FIBROUS      GRAY  BRUISES  NONE            FREE   \n",
       "\n",
       "     gill-spacing  gill-size gill-color stalk-shape   ...  \\\n",
       "1971       CROWDED     BROAD      BROWN     TAPERING  ...   \n",
       "4900         CLOSE     BROAD  CHOCOLATE    ENLARGING  ...   \n",
       "2273         CLOSE     BROAD     PURPLE     TAPERING  ...   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "1971                  WHITE                  WHITE   PARTIAL      WHITE   \n",
       "4900                  BROWN                  BROWN   PARTIAL      WHITE   \n",
       "2273                   GRAY                  WHITE   PARTIAL      WHITE   \n",
       "\n",
       "     ring-number   ring-type spore-print-color population  habitat  \\\n",
       "1971         ONE  EVANESCENT             BLACK  SCATTERED  GRASSES   \n",
       "4900         ONE       LARGE         CHOCOLATE   SOLITARY    PATHS   \n",
       "2273         ONE     PENDANT             BROWN   SOLITARY    WOODS   \n",
       "\n",
       "     edible_class  \n",
       "1971       EDIBLE  \n",
       "4900    POISONOUS  \n",
       "2273       EDIBLE  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = X_train.copy()\n",
    "train['edible_class'] = y_train\n",
    "test = X_test.copy()\n",
    "test['edible_class'] = y_test\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count|edible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUNDANT</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALMOND</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANISE</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATTACHED</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count|edible\n",
       "0         ?           470\n",
       "1  ABUNDANT           342\n",
       "2    ALMOND           244\n",
       "3     ANISE           264\n",
       "4  ATTACHED           123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_edible = pd.DataFrame(columns = ['word', 'count|edible'])\n",
    "\n",
    "for train_col in X_train.columns:\n",
    "    a = train[train['edible_class'] == 'EDIBLE'][[train_col]].value_counts().rename_axis(train_col).reset_index(name='counts')\n",
    "    a.columns = ['word', 'count|edible']\n",
    "    word_edible = pd.concat([word_edible, a], axis = 0)\n",
    "\n",
    "word_edible = word_edible.groupby(['word'], as_index=False)['count|edible'].sum()\n",
    "word_edible.index = np.arange(0, len(word_edible))\n",
    "word_edible.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count|poisonous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATTACHED</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BELL</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BROAD</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count|poisonous\n",
       "0         ?             1185\n",
       "1  ATTACHED               19\n",
       "2      BELL               28\n",
       "3     BLACK              189\n",
       "4     BROAD             1137"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_poisonous = pd.DataFrame(columns = ['word', 'count|poisonous'])\n",
    "for train_col in X_train.columns:\n",
    "    a = train[train['edible_class'] == 'POISONOUS'][[train_col]].value_counts().rename_axis(train_col).reset_index(name='counts')\n",
    "    a.columns = ['word', 'count|poisonous']\n",
    "    word_poisonous = pd.concat([word_poisonous, a], axis = 0)\n",
    "word_poisonous = word_poisonous.groupby(['word'], as_index=False)['count|poisonous'].sum()    \n",
    "word_poisonous.index = np.arange(0, len(word_poisonous))\n",
    "word_poisonous.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count|edible</th>\n",
       "      <th>count|poisonous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>470.0</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUNDANT</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALMOND</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANISE</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATTACHED</td>\n",
       "      <td>123.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>GROOVES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>LARGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>MUSTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PUNGENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SPICY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count|edible  count|poisonous\n",
       "0          ?         470.0           1185.0\n",
       "1   ABUNDANT         342.0              0.0\n",
       "2     ALMOND         244.0              0.0\n",
       "3      ANISE         264.0              0.0\n",
       "4   ATTACHED         123.0             19.0\n",
       "..       ...           ...              ...\n",
       "63   GROOVES           0.0              3.0\n",
       "64     LARGE           0.0            874.0\n",
       "65     MUSTY           0.0             36.0\n",
       "66   PUNGENT           0.0            176.0\n",
       "67     SPICY           0.0            390.0\n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.merge(word_edible, word_poisonous, how = 'outer').fillna(0)\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5306595365418895 0.46934046345811054\n"
     ]
    }
   ],
   "source": [
    "P_edible = y_train.value_counts()[0] / len(X_train) # P(edible)\n",
    "P_poisonous = y_train.value_counts()[1] / len(X_train) # P(poisonous)\n",
    "print(P_edible, P_poisonous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130988.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edible_words = word_df[['count|edible']].sum()[0]\n",
    "poisonous_words = word_df[['count|edible']].sum()[0]\n",
    "total_words = edible_words + poisonous_words\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0035995388925787663, 0.0026223576025467786, 0.0018742031773660384]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edible_likelihoods = []\n",
    "for i in range(len(word_df)):\n",
    "    numerator = word_df.loc[i,\"count|edible\"] + 1.5\n",
    "    denominator = total_words + 1\n",
    "    result = numerator / denominator\n",
    "    edible_likelihoods.append(result)\n",
    "edible_likelihoods[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009058012504866821, 1.1451343242562353e-05, 1.1451343242562353e-05]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisonous_likelihoods = []\n",
    "for i in range(len(word_df)):\n",
    "    numerator = word_df.loc[i,\"count|poisonous\"] + 1.5\n",
    "    denominator = total_words + 1\n",
    "    result = numerator / denominator\n",
    "    poisonous_likelihoods.append(result)\n",
    "poisonous_likelihoods[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "edible_posterior = np.array(edible_likelihoods) * P_edible\n",
    "poisonous_posterior = np.array(poisonous_likelihoods) * P_poisonous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edible_likelihood</th>\n",
       "      <th>poisonous_likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.009054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABUNDANT</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALMOND</th>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANISE</th>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTACHED</th>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GROOVES</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARGE</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.006680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUSTY</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNGENT</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPICY</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          edible_likelihood  poisonous_likelihood\n",
       "words                                            \n",
       "?                  0.003596              0.009054\n",
       "ABUNDANT           0.002619              0.000008\n",
       "ALMOND             0.001870              0.000008\n",
       "ANISE              0.002023              0.000008\n",
       "ATTACHED           0.000947              0.000153\n",
       "...                     ...                   ...\n",
       "GROOVES            0.000008              0.000031\n",
       "LARGE              0.000008              0.006680\n",
       "MUSTY              0.000008              0.000282\n",
       "PUNGENT            0.000008              0.001351\n",
       "SPICY              0.000008              0.002985\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_df = pd.DataFrame({'words': word_df['word'].values, \n",
    "                              'edible_likelihood': edible_likelihoods, 'poisonous_likelihood': poisonous_likelihoods}).set_index(['words'])\n",
    "likelihood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0035279876744077e-39,\n",
       " 7.188319368338135e-92,\n",
       " 4.928214884384717e-131,\n",
       " 5.707554923153211e-172,\n",
       " 3.3466429889450113e-220,\n",
       " 7.106703054541854e-270,\n",
       " 4.4501341534e-313,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edible_posterior = 1\n",
    "edible_results = []\n",
    "for i in range(0,len(X_test)):\n",
    "    for naive_word in X_test.iloc[i].values:\n",
    "        word_likelihood = likelihood_df.loc[naive_word, 'edible_likelihood']\n",
    "        edible_posterior = edible_posterior * word_likelihood\n",
    "    \n",
    "    edible_posterior = edible_posterior * P_edible\n",
    "    edible_results.append(edible_posterior)\n",
    "edible_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-01cb5a7e20e3>:6: RuntimeWarning: overflow encountered in double_scalars\n",
      "  poisonous_posterior *= word_likelihood\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[162699603992873.25,\n",
       " 1.139799419936939e+28,\n",
       " 2.374409574777128e+42,\n",
       " 6.998784884272445e+56,\n",
       " 1.4843513231017438e+70,\n",
       " 3.8974549289112324e+83,\n",
       " 2.9623787701787434e+97,\n",
       " 1.6945795576555007e+111,\n",
       " 3.491091943082844e+126,\n",
       " 2.1947521400333924e+140,\n",
       " 1.2860940521300326e+155,\n",
       " 2.824541864513109e+168,\n",
       " 2.342387144522317e+182,\n",
       " 4.0904403780372775e+196,\n",
       " 6.58226210765503e+209,\n",
       " 5.410289774999722e+223,\n",
       " 6.056163494627076e+236,\n",
       " 3.341136314037183e+250,\n",
       " 5.152483976161479e+263,\n",
       " 3.697440482208385e+277,\n",
       " 3.0397028925800684e+290,\n",
       " 1.2813672198063967e+304,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " inf,\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisonous_posterior = 1\n",
    "poisonous_results = []\n",
    "for i in range(0,len(X_test)):\n",
    "    for naive_word in X_test.iloc[i].values:\n",
    "        word_likelihood = likelihood_df.loc[naive_word, 'poisonous_likelihood']\n",
    "        poisonous_posterior *= word_likelihood\n",
    "    poisonous_posterior *= P_poisonous\n",
    "    poisonous_results.append(poisonous_posterior)\n",
    "poisonous_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in range(len(edible_results)):\n",
    "    if edible_results[i] >= poisonous_results[i]:\n",
    "        prediction.append(\"EDIBLE\")\n",
    "    else:\n",
    "        prediction.append(\"POISONOUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edible_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8243</th>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     edible_class\n",
       "1971       EDIBLE\n",
       "4900    POISONOUS\n",
       "2273       EDIBLE\n",
       "763        EDIBLE\n",
       "7663    POISONOUS\n",
       "...           ...\n",
       "5228    POISONOUS\n",
       "8243       EDIBLE\n",
       "1611       EDIBLE\n",
       "4595    POISONOUS\n",
       "7315    POISONOUS\n",
       "\n",
       "[2805 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-04ba81a4ceba>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['prediction'] = prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edible_class</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>POISONOUS</td>\n",
       "      <td>POISONOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>POISONOUS</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>POISONOUS</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8243</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>EDIBLE</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>POISONOUS</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>POISONOUS</td>\n",
       "      <td>EDIBLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     edible_class prediction\n",
       "1971       EDIBLE     EDIBLE\n",
       "4900    POISONOUS  POISONOUS\n",
       "2273       EDIBLE     EDIBLE\n",
       "763        EDIBLE     EDIBLE\n",
       "7663    POISONOUS     EDIBLE\n",
       "...           ...        ...\n",
       "5228    POISONOUS     EDIBLE\n",
       "8243       EDIBLE     EDIBLE\n",
       "1611       EDIBLE     EDIBLE\n",
       "4595    POISONOUS     EDIBLE\n",
       "7315    POISONOUS     EDIBLE\n",
       "\n",
       "[2805 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['prediction'] = prediction\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
