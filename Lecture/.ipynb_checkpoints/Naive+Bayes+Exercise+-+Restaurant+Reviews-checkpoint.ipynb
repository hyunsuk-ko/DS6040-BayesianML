{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \n",
    "file = \"ReviewWords.csv\"\n",
    "reviews = pd.read_csv(path+file, index_col = \"Word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classification\n",
    "# Training \n",
    "\n",
    "# Priors\n",
    "# Uninformed priors\n",
    "# priors = np.array([1/3,1/3,1/3])\n",
    "\n",
    "# Informed priors\n",
    "Nreviews = np.array([2895,2015,1090])\n",
    "TotalReviews = sum(Nreviews)\n",
    "priors = Nreviews/TotalReviews \n",
    "\n",
    "# Probability of Words given review type\n",
    "\n",
    "WordSums = reviews.sum(0) # number of words in each review category\n",
    "\n",
    "v = len(reviews.index)# number of distinct words in the data\n",
    "α = 1.5 # smoothing parameter\n",
    "\n",
    "\n",
    "Pword = np.zeros([len(reviews.index), len(reviews.columns)])\n",
    "for i in range(len(reviews.index)):\n",
    "    for j in range(len(reviews.columns)):\n",
    "        Pword[i,j] = (reviews.iloc[i,j] + α)/(WordSums[j] + v*α)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classification\n",
    "# Classification of new review\n",
    "\n",
    "NewReview = [\"we\", \"liked\", \"the\", 'tasty', \"calamari\"]\n",
    "\n",
    "# Match words with the words in the corpus\n",
    "\n",
    "WordsIndex = list()\n",
    "for i in range(len(NewReview)):\n",
    "    for j in range(len(reviews.index)):\n",
    "        if NewReview[i] == reviews.index[j].strip():\n",
    "            WordsIndex.append(j)\n",
    "\n",
    "# Likelihoods\n",
    "\n",
    "likelihoods = np.ones(len(reviews.columns))\n",
    "for j in range(len(reviews.columns)):\n",
    "    for i in WordsIndex:\n",
    "        likelihoods[j] = likelihoods[j]*Pword[i,j]\n",
    "\n",
    "# Posterior Probabilities\n",
    "\n",
    "numerator = likelihoods * priors\n",
    "postprob = np.round(numerator/numerator.sum(), 4)\n",
    "postprob\n",
    "\n",
    "for i in range(len(reviews.columns)):\n",
    "        print(reviews.columns[i] + ': ' + str(postprob[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
